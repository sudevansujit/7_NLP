{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Text normalization\n",
    "- Reducing word to base form\n",
    "- A word based on its intended meaning\n",
    "- Stemming\n",
    "> cutting suffix and prefix to convert to its base form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "study studious student studio studying"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(\"study studious student studio studying\")\n",
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study study VERB\n",
      "studious studious ADJ\n",
      "student student NOUN\n",
      "studio studio NOUN\n",
      "studying study VERB\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "walk walking walker was be were go going gone"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2 = nlp(\"walk walking walker was be were go going gone\")\n",
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk walk VERB\n",
      "walking walk VERB\n",
      "walker walker NOUN\n",
      "was be VERB\n",
      "be be VERB\n",
      "were be VERB\n",
      "go go VERB\n",
      "going go VERB\n",
      "gone go VERB\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token.text, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing doc_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Through the International Food Safety Authorities Network (INFOSAN),\n",
       "national food safety authorities are seeking more information on the\n",
       "potential for persistence of SARS-CoV-2, which causes COVID-19, on foods\n",
       "traded internationally as well as the potential role of food in the transmission\n",
       "of the virus. Currently, there are investigations conducted to evaluate the\n",
       "viability and survival time of SARS-CoV-2. As a general rule, the consumption\n",
       "of raw or undercooked animal products should be avoided. Raw meat, raw\n",
       "milk or raw animal organs should be handled with care to avoid crosscontamination with uncooked foods."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_covid = nlp(open('covid19.txt').read())\n",
    "doc_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Through\tthrough\tADP\n",
      "authorities\tauthority\tNOUN\n",
      "are\tbe\tVERB\n",
      "seeking\tseek\tVERB\n",
      "causes\tcause\tVERB\n",
      "foods\tfood\tNOUN\n",
      "traded\ttrade\tVERB\n",
      "Currently\tcurrently\tADV\n",
      "are\tbe\tVERB\n",
      "investigations\tinvestigation\tNOUN\n",
      "conducted\tconduct\tVERB\n",
      "As\tas\tADP\n",
      "products\tproduct\tNOUN\n",
      "avoided\tavoid\tVERB\n",
      "Raw\traw\tADJ\n",
      "organs\torgan\tNOUN\n",
      "handled\thandle\tVERB\n",
      "foods\tfood\tNOUN\n"
     ]
    }
   ],
   "source": [
    "for token in doc_covid:\n",
    "    if token.text != token.lemma_:\n",
    "        print(token.text, token.lemma_, token.pos_, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capital is converted to small letters\n",
    "# s is removed from Nouns\n",
    "# Verb is converted to base form\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authorities\tauthority\tNOUN\n",
      "are\tbe\tVERB\n",
      "seeking\tseek\tVERB\n",
      "causes\tcause\tVERB\n",
      "foods\tfood\tNOUN\n",
      "traded\ttrade\tVERB\n",
      "are\tbe\tVERB\n",
      "investigations\tinvestigation\tNOUN\n",
      "conducted\tconduct\tVERB\n",
      "products\tproduct\tNOUN\n",
      "avoided\tavoid\tVERB\n",
      "organs\torgan\tNOUN\n",
      "handled\thandle\tVERB\n",
      "foods\tfood\tNOUN\n"
     ]
    }
   ],
   "source": [
    "for token in doc_covid:\n",
    "    if token.text.lower() != token.lemma_.lower():\n",
    "        print(token.text, token.lemma_, token.pos_, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are\tbe\tVERB\n",
      "seeking\tseek\tVERB\n",
      "causes\tcause\tVERB\n",
      "traded\ttrade\tVERB\n",
      "are\tbe\tVERB\n",
      "conducted\tconduct\tVERB\n",
      "avoided\tavoid\tVERB\n",
      "handled\thandle\tVERB\n"
     ]
    }
   ],
   "source": [
    "for token in doc_covid:\n",
    "    if token.text.lower() != token.lemma_.lower() and token.pos_ != 'NOUN':\n",
    "        print(token.text, token.lemma_, token.pos_, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
