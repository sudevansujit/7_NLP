{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram_LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import trigrams\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import Counter\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_corpus = PlaintextCorpusReader('C:\\\\Users\\\\Dell\\\\NLP\\\\2_Python_Pandas\\\\100_Applied_NLP\\\\taleof2cities.txt', '.*' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trigram_model():\n",
    "    trigram_model = collections.defaultdict(lambda: collections.defaultdict(lambda: 0))\n",
    "    #for sentence in gutenberg.sents(\"austen-emma.txt\"):\n",
    "\n",
    "    for sentence in your_corpus.sents('.')[:1200]:\n",
    "        sentence = [word.lower() for word in sentence if word.isalpha()]  # get alpha only\n",
    "\n",
    "        for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "            trigram_model[(w1, w2)][w3] += 1\n",
    "\n",
    "        for w1_w2 in trigram_model:\n",
    "            trigram_count_4_w1w2 = float(sum(trigram_model[w1_w2].values()))\n",
    "            for w3 in trigram_model[w1_w2]:\n",
    "                trigram_model[w1_w2][w3] /= trigram_count_4_w1w2\n",
    "\n",
    "    return trigram_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(w1,w2):\n",
    "    model = build_trigram_model()\n",
    "    next_word = model[(w1,w2)]\n",
    "    predicted_words = Counter(next_word).most_common(10)\n",
    "\n",
    "    top10Predicted_words = list(zip(*predicted_words))[0]\n",
    "    probability_score = list(zip(*predicted_words))[1]\n",
    "    x_pos = np.arange(len(top10Predicted_words))\n",
    "\n",
    "    # calculate slope and intercept for the linear trend line\n",
    "    slope, intercept = np.polyfit(x_pos, probability_score, 1)\n",
    "\n",
    "    plt.bar(x_pos, probability_score,align='center')\n",
    "    plt.xticks(x_pos, top10Predicted_words)\n",
    "    plt.title('Predicted words for  '+ w1 + ' ' + w2)\n",
    "    plt.ylabel('Probability Score')\n",
    "    plt.xlabel('Predicted Words')\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word('can', 'be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
